# Hanbok-Trend ğŸŒŸ
### A Twitter Bot that creates wordclouds and tweets them. ğŸ¦

<img src="media/readme-1.png" width="500">

This Twitter bot pulls tweets that include the keyword í•œë³µ (Hanbok: Korean traditional costume) every day at 00:00 and generates a wordcloud from them. It then tweets the wordcloud image.

After posting the image, the bot stores the image and CSV file containing the data of the tweet in the archive folder. ğŸ“ (You can find all the images and CSV files posted by the bot in the archive folder)

Additionally, it has additional features such as creating a header based on the number of tweets that contain the keyword í•œë³µ and generating a graph from it. ğŸ“ˆ

You can find the bot that was running this code for over half a year, but unfortunately, it is no longer active due to Twitter API changes that require a $100 payment. You can check it out [here](https://twitter.com/Hanbok_Trend).

## File Structure
```
Hanbok-Trend
â”œâ”€â”€ archive
â”‚   â”œâ”€â”€ csv (CSV files containing tweet data)
â”‚   â”œâ”€â”€ tags (Wordcloud images of hashtags)
â”‚   â””â”€â”€ words (Wordcloud images of tweets)
â”œâ”€â”€ header (Code for creating header images)
â”œâ”€â”€ media (Images for README.md)
â”œâ”€â”€ tweet_stream (Code for subscribing to Twitter Stream API)
â””â”€â”€ main.py (Main code)
```

## Setup ğŸ› ï¸
1. Clone this repository
1. Install dependencies
    ```
    pip install -r requirements.txt
    ```
1. Create a Twitter app and obtain the API keys
1. Run main.py (You can use run.sh)
1. If you want to use the header feature, you must run tweet_stream/main.py, which will subscribe to the Twitter Stream API and save the data to a Redis database.
1. To install Redis, check here.
1. After running tweet_stream/main.py, you can run header/main.py, which will create header images based on the data in the Redis database.
