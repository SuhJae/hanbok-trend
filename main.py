import ast
import csv
import datetime
import os
import shutil
import time

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pytz
import schedule
import tweepy as tw
from PIL import Image
from konlpy.tag import Okt
from tqdm import tqdm
from wordcloud import WordCloud

file = "data.csv"
to_pull = 1500  # amount of tweets to pull for each run

# Twitter API credentials
# For more information, visit https://docs.tweepy.org/en/stable/authentication.html?highlight=OAuth1UserHandler#tweepy.OAuth1UserHandler
auth = tw.OAuth1UserHandler(
    "consumer_key", "consumer_secret",
    "access_token", "access_token_secret"
)
api = tw.API(auth, wait_on_rate_limit=True)


# open csv file
def save_to_csv():
    global id, name, screen_name, text, created_at, retweet_count, favorite_count, hashtags, file
    fields = [id, name, screen_name, text, created_at, retweet_count, favorite_count, hashtags]
    with open(file, 'a') as f:
        writer = csv.writer(f)
        writer.writerow(fields)


# function that pulls tweets
def get_data():
    print("Started collecting data.")
    global id, name, screen_name, text, created_at, retweet_count, favorite_count, hashtags, file
    with open(file, 'w') as f:
        writer = csv.writer(f)
        writer.writerow(
            ["id", "name", "screen_name", "text", "created_at", "retweet_count", "favorite_count", "hashtags"])
    i = 0
    tweets = tw.Cursor(api.search_tweets, q="í•œë³µ", lang="ko").items(to_pull)

    try:
        for tweet in tqdm(tweets, total=to_pull):
            i = i + 1
            id = tweet.id
            created_at = tweet.created_at
            screen_name = tweet.user.screen_name
            name = tweet.user.name
            text = tweet.text
            retweet_count = tweet.retweet_count
            favorite_count = tweet.favorite_count
            hashtags = tweet.entities['hashtags']
            save_to_csv()
            # print(f"Pulled tweet {id}. {i}/{to_pull} ({round(i / to_pull * 100, 3)})%")
        print("Completed collecting data.\n")
    except:
        print("Failed collecting data. Trying again in 3 seconds.")
        time.sleep(3)
        get_data()


# function that renders wordcloud using data from csv file (for words)
def render_words():
    print("Started rendering")
    global id, name, screen_name, text, created_at, retweet_count, favorite_count, hashtags, file, app, apperernc, words
    df = pd.read_csv(file, encoding='utf-8', header=0)
    # wc = df.set_index("text").to_dict()["text"]

    content_all = ''
    for i in range(len(df["text"])):
        content_all = content_all + " " + df["text"].loc[i]
    content_all = str(content_all)

    print("Completed reading csv.")

    okt = Okt()
    nouns_txt = okt.nouns(content_all)
    print("Completed extracting nouns.")

    # remove 1-letter words
    nouns_txt = [noun for noun in nouns_txt if len(noun) > 1]

    stopword = ["ê°€", "ê°€ê¹ŒìŠ¤ë¡œ", "ê°€ë ¹", "ê°", "ê°ê°", "ê°ì", "ê°ì¢…", "ê°–ê³ ë§í•˜ìë©´", "ê°™ë‹¤", "ê°™ì´", "ê°œì˜ì¹˜ì•Šê³ ", "ê±°ë‹ˆì™€", "ê±°ë°”", "ê±°ì˜", "ê²ƒ",
                "ê²ƒê³¼ ê°™ì´",
                "ê²ƒë“¤", "ê²Œë‹¤ê°€", "ê²Œìš°ë‹¤", "ê²¨ìš°", "ê²¬ì§€ì—ì„œ", "ê²°ê³¼ì— ì´ë¥´ë‹¤", "ê²°êµ­", "ê²°ë¡ ì„ ë‚¼ ìˆ˜ ìˆë‹¤", "ê²¸ì‚¬ê²¸ì‚¬", "ê³ ë ¤í•˜ë©´", "ê³ ë¡œ", "ê³§", "ê³µë™ìœ¼ë¡œ", "ê³¼",
                "ê³¼ì—°", "ê´€ê³„ê°€ ìˆë‹¤", "ê´€ê³„ì—†ì´", "ê´€ë ¨ì´ ìˆë‹¤", "ê´€í•˜ì—¬", "ê´€í•œ", "ê´€í•´ì„œëŠ”", "êµ¬", "êµ¬ì²´ì ìœ¼ë¡œ", "êµ¬í† í•˜ë‹¤", "ê·¸", "ê·¸ë“¤", "ê·¸ë•Œ", "ê·¸ë˜",
                "ê·¸ë˜ë„",
                "ê·¸ë˜ì„œ", "ê·¸ëŸ¬ë‚˜", "ê·¸ëŸ¬ë‹ˆ", "ê·¸ëŸ¬ë‹ˆê¹Œ", "ê·¸ëŸ¬ë©´", "ê·¸ëŸ¬ë¯€ë¡œ", "ê·¸ëŸ¬í•œì¦‰", "ê·¸ëŸ° ê¹Œë‹­ì—", "ê·¸ëŸ°ë°", "ê·¸ëŸ°ì¦‰", "ê·¸ëŸ¼", "ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ ",
                "ê·¸ë ‡ê²Œ í•¨ìœ¼ë¡œì¨",
                "ê·¸ë ‡ì§€", "ê·¸ë ‡ì§€ ì•Šë‹¤ë©´", "ê·¸ë ‡ì§€ ì•Šìœ¼ë©´", "ê·¸ë ‡ì§€ë§Œ", "ê·¸ë ‡ì§€ì•Šìœ¼ë©´", "ê·¸ë¦¬ê³ ", "ê·¸ë¦¬í•˜ì—¬", "ê·¸ë§Œì´ë‹¤", "ê·¸ì— ë”°ë¥´ëŠ”", "ê·¸ìœ„ì—", "ê·¸ì €", "ê·¸ì¤‘ì—ì„œ",
                "ê·¸ì¹˜ì§€ ì•Šë‹¤", "ê·¼ê±°ë¡œ", "ê·¼ê±°í•˜ì—¬", "ê¸°ëŒ€ì—¬", "ê¸°ì ìœ¼ë¡œ", "ê¸°ì¤€ìœ¼ë¡œ", "ê¸°íƒ€", "ê¹Œë‹­ìœ¼ë¡œ", "ê¹Œì•…", "ê¹Œì§€", "ê¹Œì§€ ë¯¸ì¹˜ë‹¤", "ê¹Œì§€ë„", "ê½ˆë‹¹", "ë™ë™",
                "ë¼ìµ", "ë‚˜", "ë‚˜ë¨¸ì§€ëŠ”", "ë‚¨ë“¤", "ë‚¨ì§“", "ë„ˆ", "ë„ˆí¬", "ë„ˆí¬ë“¤", "ë„¤", "ë„·", "ë…„", "ë…¼í•˜ì§€ ì•Šë‹¤", "ë†€ë¼ë‹¤", "ëˆ„ê°€ ì•Œê² ëŠ”ê°€", "ëˆ„êµ¬", "ë‹¤ë¥¸",
                "ë‹¤ë¥¸ ë°©ë©´ìœ¼ë¡œ", "ë‹¤ë§Œ", "ë‹¤ì„¯", "ë‹¤ì†Œ", "ë‹¤ìˆ˜", "ë‹¤ì‹œ ë§í•˜ìë©´", "ë‹¤ì‹œë§í•˜ë©´", "ë‹¤ìŒ", "ë‹¤ìŒì—", "ë‹¤ìŒìœ¼ë¡œ", "ë‹¨ì§€", "ë‹µë‹¤", "ë‹¹ì‹ ", "ë‹¹ì¥",
                "ëŒ€ë¡œ í•˜ë‹¤", "ëŒ€í•˜ë©´", "ëŒ€í•˜ì—¬", "ëŒ€í•´ ë§í•˜ìë©´", "ëŒ€í•´ì„œ", "ëŒ•ê·¸", "ë”êµ¬ë‚˜", "ë”êµ°ë‹¤ë‚˜", "ë”ë¼ë„", "ë”ë¶ˆì–´", "ë”ìš±ë”", "ë”ìš±ì´ëŠ”", "ë„ë‹¬í•˜ë‹¤",
                "ë„ì°©í•˜ë‹¤",
                "ë™ì‹œì—", "ë™ì•ˆ", "ëœë°”ì—ì•¼", "ëœì´ìƒ", "ë‘ë²ˆì§¸ë¡œ", "ë‘˜", "ë‘¥ë‘¥", "ë’¤ë”°ë¼", "ë’¤ì´ì–´", "ë“ ê°„ì—", "ë“¤", "ë“±", "ë“±ë“±", "ë”©ë™", "ë”°ë¼", "ë”°ë¼ì„œ",
                "ë”°ìœ„", "ë”°ì§€ì§€ ì•Šë‹¤", "ë”±", "ë•Œ", "ë•Œê°€ ë˜ì–´", "ë•Œë¬¸ì—", "ë˜", "ë˜í•œ", "ëšëš", "ë¼ í•´ë„", "ë ¹", "ë¡œ", "ë¡œ ì¸í•˜ì—¬", "ë¡œë¶€í„°", "ë¡œì¨", "ë¥™",
                "ë¥¼", "ë§ˆìŒëŒ€ë¡œ", "ë§ˆì €", "ë§ˆì €ë„", "ë§ˆì¹˜", "ë§‰ë¡ í•˜ê³ ", "ë§Œ ëª»í•˜ë‹¤", "ë§Œì•½", "ë§Œì•½ì—", "ë§Œì€ ì•„ë‹ˆë‹¤", "ë§Œì´ ì•„ë‹ˆë‹¤", "ë§Œì¼", "ë§Œí¼", "ë§í•˜ìë©´",
                "ë§í• ê²ƒë„ ì—†ê³ ", "ë§¤", "ë§¤ë²ˆ", "ë©”ì“°ê²ë‹¤", "ëª‡", "ëª¨", "ëª¨ë‘", "ë¬´ë µ", "ë¬´ë¦ì“°ê³ ", "ë¬´ìŠ¨", "ë¬´ì—‡", "ë¬´ì—‡ë•Œë¬¸ì—", "ë¬¼ë¡ ", "ë°", "ë°”ê¾¸ì–´ë§í•˜ë©´",
                "ë°”ê¾¸ì–´ë§í•˜ìë©´", "ë°”ê¾¸ì–´ì„œ ë§í•˜ë©´", "ë°”ê¾¸ì–´ì„œ í•œë‹¤ë©´", "ë°”ê¿” ë§í•˜ë©´", "ë°”ë¡œ", "ë°”ì™€ê°™ì´", "ë°–ì— ì•ˆëœë‹¤", "ë°˜ëŒ€ë¡œ", "ë°˜ëŒ€ë¡œ ë§í•˜ìë©´", "ë°˜ë“œì‹œ", "ë²„ê¸ˆ",
                "ë³´ëŠ”ë°ì„œ", "ë³´ë‹¤ë”", "ë³´ë“œë“", "ë³¸ëŒ€ë¡œ", "ë´", "ë´ë¼", "ë¶€ë¥˜ì˜ ì‚¬ëŒë“¤", "ë¶€í„°", "ë¶ˆêµ¬í•˜ê³ ", "ë¶ˆë¬¸í•˜ê³ ", "ë¶•ë¶•", "ë¹„ê±±ê±°ë¦¬ë‹¤", "ë¹„êµì ", "ë¹„ê¸¸ìˆ˜ ì—†ë‹¤",
                "ë¹„ë¡œì†Œ", "ë¹„ë¡", "ë¹„ìŠ·í•˜ë‹¤", "ë¹„ì¶”ì–´ ë³´ì•„", "ë¹„í•˜ë©´", "ë¿ë§Œ ì•„ë‹ˆë¼", "ë¿ë§Œì•„ë‹ˆë¼", "ë¿ì´ë‹¤", "ì‚ê±±", "ì‚ê±±ê±°ë¦¬ë‹¤", "ì‚¬", "ì‚¼", "ìƒëŒ€ì ìœ¼ë¡œ ë§í•˜ìë©´",
                "ìƒê°í•œëŒ€ë¡œ", "ì„¤ë ¹", "ì„¤ë§ˆ", "ì„¤ì‚¬", "ì…‹", "ì†Œìƒ", "ì†Œì¸", "ì†¨", "ì‰¿", "ìŠµë‹ˆê¹Œ", "ìŠµë‹ˆë‹¤", "ì‹œê°", "ì‹œê°„", "ì‹œì‘í•˜ì—¬", "ì‹œì´ˆì—", "ì‹œí‚¤ë‹¤",
                "ì‹¤ë¡œ",
                "ì‹¬ì§€ì–´", "ì•„", "ì•„ë‹ˆ", "ì•„ë‹ˆë‚˜ë‹¤ë¥¼ê°€", "ì•„ë‹ˆë¼ë©´", "ì•„ë‹ˆë©´", "ì•„ë‹ˆì—ˆë‹¤ë©´", "ì•„ë˜ìœ—", "ì•„ë¬´ê±°ë‚˜", "ì•„ë¬´ë„", "ì•„ì•¼", "ì•„ìš¸ëŸ¬", "ì•„ì´", "ì•„ì´ê³ ",
                "ì•„ì´êµ¬",
                "ì•„ì´ì•¼", "ì•„ì´ì¿ ", "ì•„í•˜", "ì•„í™‰", "ì•ˆ ê·¸ëŸ¬ë©´", "ì•Šê¸° ìœ„í•˜ì—¬", "ì•Šê¸° ìœ„í•´ì„œ", "ì•Œ ìˆ˜ ìˆë‹¤", "ì•Œì•˜ì–´", "ì•—", "ì•ì—ì„œ", "ì•ì˜ê²ƒ", "ì•¼", "ì•½ê°„",
                "ì–‘ì",
                "ì–´", "ì–´ê¸°ì—¬ì°¨", "ì–´ëŠ", "ì–´ëŠ ë…„ë„", "ì–´ëŠê²ƒ", "ì–´ëŠê³³", "ì–´ëŠë•Œ", "ì–´ëŠìª½", "ì–´ëŠí•´", "ì–´ë””", "ì–´ë•Œ", "ì–´ë– í•œ", "ì–´ë–¤", "ì–´ë–¤ê²ƒ", "ì–´ë–¤ê²ƒë“¤",
                "ì–´ë–»ê²Œ", "ì–´ë–»í•´", "ì–´ì´", "ì–´ì§¸ì„œ", "ì–´ì¨‹ë“ ", "ì–´ì©”ìˆ˜ ì—†ë‹¤", "ì–´ì°Œ", "ì–´ì°Œëë“ ", "ì–´ì°Œëì–´", "ì–´ì°Œí•˜ë“ ì§€", "ì–´ì°Œí•˜ì—¬", "ì–¸ì œ", "ì–¸ì  ê°€", "ì–¼ë§ˆ",
                "ì–¼ë§ˆ ì•ˆ ë˜ëŠ” ê²ƒ", "ì–¼ë§ˆê°„", "ì–¼ë§ˆë‚˜", "ì–¼ë§ˆë“ ì§€", "ì–¼ë§ˆë§Œí¼", "ì–¼ë§ˆí¼", "ì—‰ì—‰", "ì—", "ì— ê°€ì„œ", "ì— ë‹¬ë ¤ ìˆë‹¤", "ì— ëŒ€í•´", "ì— ìˆë‹¤", "ì— í•œí•˜ë‹¤",
                "ì—ê²Œ", "ì—ì„œ", "ì—¬", "ì—¬ê¸°", "ì—¬ëŸ", "ì—¬ëŸ¬ë¶„", "ì—¬ë³´ì‹œì˜¤", "ì—¬ë¶€", "ì—¬ì„¯", "ì—¬ì „íˆ", "ì—¬ì°¨", "ì—°ê´€ë˜ë‹¤", "ì—°ì´ì„œ", "ì˜", "ì˜ì°¨", "ì˜†ì‚¬ëŒ",
                "ì˜ˆ",
                "ì˜ˆë¥¼ ë“¤ë©´", "ì˜ˆë¥¼ ë“¤ìë©´", "ì˜ˆì»¨ëŒ€", "ì˜ˆí•˜ë©´", "ì˜¤", "ì˜¤ë¡œì§€", "ì˜¤ë¥´ë‹¤", "ì˜¤ìë§ˆì", "ì˜¤ì§", "ì˜¤í˜¸", "ì˜¤íˆë ¤", "ì™€", "ì™€ ê°™ì€ ì‚¬ëŒë“¤", "ì™€ë¥´ë¥´",
                "ì™€ì•„", "ì™œ", "ì™œëƒí•˜ë©´", "ì™¸ì—ë„", "ìš”ë§Œí¼", "ìš”ë§Œí•œ ê²ƒ", "ìš”ë§Œí•œê±¸", "ìš”ì»¨ëŒ€", "ìš°ë¥´ë¥´", "ìš°ë¦¬", "ìš°ë¦¬ë“¤", "ìš°ì„ ", "ìš°ì— ì¢…í•©í•œê²ƒê³¼ê°™ì´", "ìš´ìš´",
                "ì›”",
                "ìœ„ì—ì„œ ì„œìˆ í•œë°”ì™€ê°™ì´", "ìœ„í•˜ì—¬", "ìœ„í•´ì„œ", "ìœ™ìœ™", "ìœ¡", "ìœ¼ë¡œ", "ìœ¼ë¡œ ì¸í•˜ì—¬", "ìœ¼ë¡œì„œ", "ìœ¼ë¡œì¨", "ì„", "ì‘", "ì‘ë‹¹", "ì˜", "ì˜ê±°í•˜ì—¬",
                "ì˜ì§€í•˜ì—¬",
                "ì˜í•´", "ì˜í•´ë˜ë‹¤", "ì˜í•´ì„œ", "ì´", "ì´ ë˜ë‹¤", "ì´ ë•Œë¬¸ì—", "ì´ ë°–ì—", "ì´ ì™¸ì—", "ì´ ì •ë„ì˜", "ì´ê²ƒ", "ì´ê³³", "ì´ë•Œ", "ì´ë¼ë©´", "ì´ë˜",
                "ì´ëŸ¬ì´ëŸ¬í•˜ë‹¤", "ì´ëŸ¬í•œ", "ì´ëŸ°", "ì´ëŸ´ì •ë„ë¡œ", "ì´ë ‡ê²Œ ë§ì€ ê²ƒ", "ì´ë ‡ê²Œë˜ë©´", "ì´ë ‡ê²Œë§í•˜ìë©´", "ì´ë ‡êµ¬ë‚˜", "ì´ë¡œ ì¸í•˜ì—¬", "ì´ë¥´ê¸°ê¹Œì§€", "ì´ë¦¬í•˜ì—¬",
                "ì´ë§Œí¼",
                "ì´ë²ˆ", "ì´ë´", "ì´ìƒ", "ì´ì–´ì„œ", "ì´ì—ˆë‹¤", "ì´ì™€ ê°™ë‹¤", "ì´ì™€ ê°™ì€", "ì´ì™€ ë°˜ëŒ€ë¡œ", "ì´ì™€ê°™ë‹¤ë©´", "ì´ì™¸ì—ë„", "ì´ìš©í•˜ì—¬", "ì´ìœ ë§Œìœ¼ë¡œ", "ì´ì  ",
                "ì´ì§€ë§Œ",
                "ì´ìª½", "ì´ì²œêµ¬", "ì´ì²œìœ¡", "ì´ì²œì¹ ", "ì´ì²œíŒ”", "ì¸ ë“¯í•˜ë‹¤", "ì¸ì  ", "ì¼", "ì¼ê²ƒì´ë‹¤", "ì¼ê³±", "ì¼ë‹¨", "ì¼ë•Œ", "ì¼ë°˜ì ìœ¼ë¡œ", "ì¼ì§€ë¼ë„",
                "ì„ì— í‹€ë¦¼ì—†ë‹¤",
                "ì…ê°í•˜ì—¬", "ì…ì¥ì—ì„œ", "ì‡ë”°ë¼", "ìˆë‹¤", "ì", "ìê¸°", "ìê¸°ì§‘", "ìë§ˆì", "ìì‹ ", "ì ê¹", "ì ì‹œ", "ì €", "ì €ê²ƒ", "ì €ê²ƒë§Œí¼", "ì €ê¸°", "ì €ìª½",
                "ì €í¬", "ì „ë¶€", "ì „ì", "ì „í›„", "ì ì—ì„œ ë³´ì•„", "ì •ë„ì— ì´ë¥´ë‹¤", "ì œ", "ì œê°ê¸°", "ì œì™¸í•˜ê³ ", "ì¡°ê¸ˆ", "ì¡°ì°¨", "ì¡°ì°¨ë„", "ì¡¸ì¡¸", "ì¢€", "ì¢‹ì•„",
                "ì¢ì¢",
                "ì£¼ë£©ì£¼ë£©", "ì£¼ì €í•˜ì§€ ì•Šê³ ", "ì¤„ì€ ëª°ëë‹¤", "ì¤„ì€ëª¨ë¥¸ë‹¤", "ì¤‘ì—ì„œ", "ì¤‘ì˜í•˜ë‚˜", "ì¦ˆìŒí•˜ì—¬", "ì¦‰", "ì¦‰ì‹œ", "ì§€ë“ ì§€", "ì§€ë§Œ", "ì§€ë§ê³ ", "ì§„ì§œë¡œ",
                "ìª½ìœ¼ë¡œ",
                "ì°¨ë¼ë¦¬", "ì°¸", "ì°¸ë‚˜", "ì²«ë²ˆì§¸ë¡œ", "ì³‡", "ì´ì ìœ¼ë¡œ", "ì´ì ìœ¼ë¡œ ë§í•˜ë©´", "ì´ì ìœ¼ë¡œ ë³´ë©´", "ì¹ ", "ì½¸ì½¸", "ì¾…ì¾…", "ì¿µ", "íƒ€ë‹¤", "íƒ€ì¸", "íƒ•íƒ•",
                "í† í•˜ë‹¤", "í†µí•˜ì—¬", "íˆ­", "í‰¤", "í‹ˆíƒ€", "íŒ", "íŒ”", "í½", "í„ë ", "í•˜", "í•˜ê²Œë ê²ƒì´ë‹¤", "í•˜ê²Œí•˜ë‹¤", "í•˜ê² ëŠ”ê°€", "í•˜ê³  ìˆë‹¤", "í•˜ê³ ìˆì—ˆë‹¤",
                "í•˜ê³¤í•˜ì˜€ë‹¤", "í•˜êµ¬ë‚˜", "í•˜ê¸° ë•Œë¬¸ì—", "í•˜ê¸° ìœ„í•˜ì—¬", "í•˜ê¸°ëŠ”í•œë°", "í•˜ê¸°ë§Œ í•˜ë©´", "í•˜ê¸°ë³´ë‹¤ëŠ”", "í•˜ê¸°ì—", "í•˜ë‚˜", "í•˜ëŠë‹ˆ", "í•˜ëŠ” ê¹€ì—", "í•˜ëŠ” í¸ì´ ë‚«ë‹¤",
                "í•˜ëŠ”ê²ƒë„", "í•˜ëŠ”ê²ƒë§Œ ëª»í•˜ë‹¤", "í•˜ëŠ”ê²ƒì´ ë‚«ë‹¤", "í•˜ëŠ”ë°”", "í•˜ë”ë¼ë„", "í•˜ë„ë‹¤", "í•˜ë„ë¡ì‹œí‚¤ë‹¤", "í•˜ë„ë¡í•˜ë‹¤", "í•˜ë“ ì§€", "í•˜ë ¤ê³ í•˜ë‹¤", "í•˜ë§ˆí„°ë©´",
                "í•˜ë©´ í• ìˆ˜ë¡",
                "í•˜ë©´ëœë‹¤", "í•˜ë©´ì„œ", "í•˜ë¬¼ë©°", "í•˜ì—¬ê¸ˆ", "í•˜ì—¬ì•¼", "í•˜ìë§ˆì", "í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´", "í•˜ì§€ ì•Šë„ë¡", "í•˜ì§€ë§ˆ", "í•˜ì§€ë§ˆë¼", "í•˜ì§€ë§Œ", "í•˜í•˜", "í•œ ê¹Œë‹­ì—",
                "í•œ ì´ìœ ëŠ”", "í•œ í›„", "í•œë‹¤ë©´", "í•œë‹¤ë©´ ëª°ë¼ë„", "í•œë°", "í•œë§ˆë””", "í•œì ì´ìˆë‹¤", "í•œì¼ ìœ¼ë¡œëŠ”", "í•œí•­ëª©", "í•  ë”°ë¦„ì´ë‹¤", "í•  ìƒê°ì´ë‹¤", "í•  ì¤„ ì•ˆë‹¤",
                "í•  ì§€ê²½ì´ë‹¤", "í•  í˜ì´ ìˆë‹¤", "í• ë•Œ", "í• ë§Œí•˜ë‹¤", "í• ë§ì •", "í• ë¿", "í• ìˆ˜ìˆë‹¤", "í• ìˆ˜ìˆì–´", "í• ì¤„ì•Œë‹¤", "í• ì§€ë¼ë„", "í• ì§€ì–¸ì •", "í•¨ê»˜", "í•´ë„ëœë‹¤",
                "í•´ë„ì¢‹ë‹¤", "í•´ë´ìš”", "í•´ì„œëŠ” ì•ˆëœë‹¤", "í•´ì•¼í•œë‹¤", "í•´ìš”", "í–ˆì–´ìš”", "í–¥í•˜ë‹¤", "í–¥í•˜ì—¬", "í–¥í•´ì„œ", "í—ˆ", "í—ˆê±±", "í—ˆí—ˆ", "í—‰", "í—‰í—‰", "í—ë–¡í—ë–¡",
                "í˜•ì‹ìœ¼ë¡œ ì“°ì—¬", "í˜¹ì‹œ", "í˜¹ì€", "í˜¼ì", "í›¨ì”¬", "íœ˜ìµ", "íœ´", "íí", "í¥", "í˜ì…ì–´", "ê·¸ê±°", "ì§„ì§œ", "ì •ë§", "ì´ë¯¸", "ì œëŒ€ë¡œ", "ì œë°œ",
                "ë‹ˆ" "ê¸°", "ì´ì œ", "ê·¸ëƒ¥"]

    fonts = "NotoSansKR-Bold.otf"

    # remove stopwords from the nouns_list
    nouns_txt = [nouns_txt[i] for i in range(len(nouns_txt)) if nouns_txt[i] not in stopword]

    print("Completed removing stopwords.")

    icon = Image.open("mask.png")
    icon.putalpha(255)
    mask = Image.new("RGB", icon.size, (255, 255, 255))
    mask.paste(icon, icon)
    mask = np.array(mask)

    unique_string = (" ").join(nouns_txt)

    wordcloud = WordCloud(width=2048, height=1024, colormap='bwr', background_color="black", font_path=fonts,
                          max_words=500, collocations=False).generate(unique_string)
    plt.figure(figsize=(15, 8))
    plt.axis("off")

    # save the wordcloud image
    wordcloud.to_file("result.png")

    # sort the nouns_list by frequency
    apperernc = []
    words = []
    for i in range(len(nouns_txt)):
        if nouns_txt[i] not in words:
            words.append(nouns_txt[i])
            apperernc.append(1)
        else:
            apperernc[words.index(nouns_txt[i])] += 1

    # sort the words list by frequency
    apperernc, words = (list(t) for t in zip(*sorted(zip(apperernc, words))))
    # inverse the list
    apperernc = apperernc[::-1]
    words = words[::-1]

    print("Completed drawing wordcloud.\n")


# function that renders wordcloud using data from csv file (for hashtags)
def render_hashtag():
    global words, apperernc
    print("Started rendering")
    df = pd.read_csv('data.csv')

    hashtags = []

    for i in range(len(df["hashtags"])):
        tags = df["hashtags"].loc[i]

        tags = ast.literal_eval(tags)
        # Create a list of hashtags

        for i in range(len(tags)):
            hashtags.append(tags[i]["text"])

    print("Completed reading data.csv")

    stopwords = ["íŒ”ë¡œìš°", "RT", "ì´ë²¤íŠ¸", "RTë°", "ì„¹íŠ¸", "RTì´ë²¤íŠ¸", "ì„¹ìŠ¤"]
    hashtags = [hashtags[i] for i in range(len(hashtags)) if hashtags[i] not in stopwords]
    fonts = "NotoSansKR-Bold.otf"

    print("Completed filtering hashtags.")

    unique_string = (" ").join(hashtags)
    wordcloud = WordCloud(width=2048, height=1024, colormap='summer', background_color="black", font_path=fonts,
                          max_words=500, collocations=False).generate(unique_string)
    plt.figure(figsize=(15, 8))
    plt.imshow(wordcloud)
    plt.axis("off")

    # save image to a file
    wordcloud.to_file("hashtag.png")

    # sort the nouns_list by frequency
    apperernc = []
    words = []
    for i in range(len(hashtags)):
        if hashtags[i] not in words:
            words.append(hashtags[i])
            apperernc.append(1)
        else:
            apperernc[words.index(hashtags[i])] += 1

    # sort the hashtag list by frequency
    apperernc, words = (list(t) for t in zip(*sorted(zip(apperernc, words))))
    # inverse the list
    apperernc = apperernc[::-1]
    words = words[::-1]
    print("Completed drawing wordcloud.\n")


# function that sends a tweet with the wordcloud image
def post_words():
    print("Started posting.")
    global apperernc, words, to_pull
    # get time in kst time zone with pytz
    now = datetime.datetime.now(tz=pytz.timezone('Asia/Seoul'))
    year = now.year
    month = now.month
    day = now.day

    status = f"""ğŸ“Œ {year}ë…„ {month}ì›” {day}ì¼ í•œë³µ ê´€ë ¨ ë‹¨ì–´ íŠ¸ë Œë“œ ì…ë‹ˆë‹¤.

ğŸ† í•œë³µ ê´€ë ¨ ë‹¨ì–´ ë­í‚¹:
ğŸ¥‡ {words[1]} - {apperernc[1]}íšŒ
ğŸ¥ˆ {words[2]} - {apperernc[2]}íšŒ
ğŸ¥‰ {words[3]} - {apperernc[3]}íšŒ

íŠ¸ìœ— {to_pull}ê°œë¡œ ë¶„ì„ëœ ê²°ê³¼ì…ë‹ˆë‹¤."""

    update_status(status, "result.png")


def post_hashtag():
    print("Started posting.")
    global apperernc, words, to_pull
    # get time in kst time zone with pytz
    now = datetime.datetime.now(tz=pytz.timezone('Asia/Seoul'))
    year = now.year
    month = now.month
    day = now.day

    status = f"""ğŸ“Œ {year}ë…„ {month}ì›” {day}ì¼ í•œë³µ ê´€ë ¨ í•´ì‹œí…Œê·¸ íŠ¸ë Œë“œ ì…ë‹ˆë‹¤.

ğŸ† í•œë³µ í•´ì‹œí…Œê·¸ ë‹¨ì–´ ë­í‚¹:
ğŸ¥‡ #{words[1]} - {apperernc[1]}íšŒ
ğŸ¥ˆ #{words[2]} - {apperernc[2]}íšŒ
ğŸ¥‰ #{words[3]} - {apperernc[3]}íšŒ

    íŠ¸ìœ— {to_pull}ê°œë¡œ ë¶„ì„ëœ ê²°ê³¼ì…ë‹ˆë‹¤."""

    update_status(status=status, filename="hashtag.png")


def update_status(status, filename):
    try:
        api.update_status_with_media(status=status, filename=filename)
        print("Completed posting.\n")
    except:
        print("Failed posting. Trying again in 2 seconds.")
        time.sleep(2)
        update_status(status, filename)


# function that archives the wordcloud image and the csv file
def archive():
    print("Started archiving.")
    # rename the file
    now = datetime.datetime.now(tz=pytz.timezone('Asia/Seoul'))
    year = now.year
    month = now.month
    day = now.day
    hour = now.hour
    minute = now.minute
    second = now.second

    os.rename("result.png", f"{year}-{month}-{day}-{hour}-{minute}-{second}-result.png")
    os.rename("hashtag.png", f"{year}-{month}-{day}-{hour}-{minute}-{second}-hashtag.png")
    os.rename("data.csv", f"{year}-{month}-{day}-{hour}-{minute}-{second}.csv")
    # move the file to the archive folder
    shutil.move(f"{year}-{month}-{day}-{hour}-{minute}-{second}-result.png", "archive/words")
    shutil.move(f"{year}-{month}-{day}-{hour}-{minute}-{second}-hashtag.png", "archive/tags")
    shutil.move(f"{year}-{month}-{day}-{hour}-{minute}-{second}.csv", "archive/csv")
    print("Completed archiving.\n")


def start():
    print("""============================================
Timed Bot Activation
============================================""")
    get_data()
    render_words()
    post_words()
    render_hashtag()
    post_hashtag()
    archive()
    print("""============================================
Finished Loop.
============================================""")


# start the bot
schedule.every().day.at("00:00").do(start)

print("Bot Loaded!")
while True:
    schedule.run_pending()
    time.sleep(1)
